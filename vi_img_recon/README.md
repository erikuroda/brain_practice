# OpenNEURO
## [Visual image reconstruction](https://openneuro.org/datasets/ds000255/versions/00002)

uploaded by Franklin Feingold on 2018-03-29 - over 2 years ago
神谷先生(京大)
#### Task
人間の被験者が12×12枚のちらつきパッチのコントラストベースの画像を見る

画像閲覧には2種類のタスク

(1)ランダム画像表示
(2)図形画像(幾何学的形状またはアルファベット文字)表示の2種類の画像表示

画像提示は各画像の提示の間に休憩を挟んだブロックデザインを使用

ランダム画像のパッチ提示では、画像は6秒間提示され、その後6秒間の休息が与えらた

図形画像の提示では、画像は12秒間提示され、その後12秒間の休息が与えられた

ランダム画像表示のデータを用いて復号化モデルの学習を行い、学習したモデルを図画像表示のデータを用いて評価

### datasets
2人の被験者（'sub-01'と'sub-02'）

2セッションのfMRI実験（'ses-01'と'ses-02'）

各セッションは、EPI画像（TR、2000 ms、TE、30 ms、フリップ角、80°、ボクセルサイズ、3×3×3×3 mm、FOV、192×192 mm、スライス数、30、スライスギャップ、0 mm）
と面内T2強調画像（TR、6000 ms、TE、57 ms、フリップ角、90°、ボクセルサイズ、0.75×0.75×3.0 mm、FOV、192×192 mm）から構成

EPI画像：後頭葉全体をカバー

データセットには、各被験者のT1強調解剖学的参照画像も含まれている（TR、2250ms、TE、サブ01で2.98ms、サブ02で3.06ms、TI、900ms、フリップ角、9°、ボクセルサイズ、1.0×1.0×1.0mm、FOV、256×256mm）。

T1w画像は、fMRI実験セッションとは異なるセッションで得られ、'ses-anat'ディレクトリに保存

T1w 画像は、pydeface (https://pypi.python.org/pypi/pydeface) によりデタッチ

すべてのDICOMファイルは、FreeSurferのmri_convertによってNifti-1ファイルに変換されている。さらに、データセットには、sourcedataディレクトリにある各被験者のROIを手動で定義したマスク画像が含まれている（詳細はsourcedataのREADMEを参照）。

ｆＭＲＩの実行中、被験者は、１２×１２のフリッカー画像パッチのコントラストベースの画像を見た。viewRandomとviewFigureの2種類の画像を使用

viewRandomでは、ランダムな画像を視覚刺激として提示

viewRandomは22回の刺激提示試行で構成され、298秒(149回)持続

2人の被験者は20回の「viewRandom」を行った

viewFigure」では、各試行で幾何学的形状パターン（正方形、小枠、大枠、プラス、X）またはアルファベット文字パターン（n、e、u、r、o）のいずれかが提示

さらに、被験者が細いアルファベット文字パターン（n, e, u, r, o）と大きいアルファベット文字パターン（n, e, u, r, o）を見ている間のデータもデータセットに含まれている（これらは元の研究の結果には含まれていない）

各'viewFigure'の実行は10回の刺激提示試行で構成され、268秒(134ボリューム)持続

sub-01」と「sub-02」はそれぞれ12回と10回の「viewFigure」を実行

被験者がまばたきを抑制し、目をしっかりと固定するために、各刺激ブロックが始まる2秒前に固定スポットの色を白から赤に変更

警戒心を確保するために、各刺激ブロックの開始から３〜５秒のランダムな間隔の後に発生した固定点の色の変化（赤から緑へ、１００ｍｓ）を検出するように被験者に指示

被験者のパフォーマンスは実験中にオンラインでモニターされたが、記録されず、データセットから省略
